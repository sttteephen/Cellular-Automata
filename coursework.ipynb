{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "1vv8l5B7G208",
        "XeiRYkFap8Ok"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMz+164a4dtIYeyAm4WtauH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sttteephen/Cellular-Automata/blob/main/coursework.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import and Split Data"
      ],
      "metadata": {
        "id": "n0cWXCUNnDhV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# imports and mount google drive\n",
        "import pandas as pd\n",
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "from google.colab import drive\n",
        "import nltk\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras import preprocessing\n",
        "from keras.preprocessing import sequence\n",
        "from keras.utils import pad_sequences\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "cwaaEPIZ1Ju4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07214ad7-d83a-478b-9df9-1352356a1291"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create dataframe from dataset and split into reviews and labels\n",
        "df_train = pd.read_csv('/content/drive/My Drive/coursework_dataset/all_data.csv', names=['reviews', 'labels'], sep=',')\n",
        "reviews = df_train['reviews'].values\n",
        "labels = df_train['labels'].values\n"
      ],
      "metadata": {
        "id": "jfQW5T5bmbRC"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create smaller dataframe from smaller dataset for exploratory analysis, split into reveiws and labels\n",
        "df_analysis = pd.read_csv('/content/drive/My Drive/coursework_dataset/train.csv', names=['reviews', 'labels'], sep=',')\n",
        "a_reviews = df_analysis['reviews'].values\n",
        "a_labels = df_analysis['labels'].values"
      ],
      "metadata": {
        "id": "ehOn5rYRpZxC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(reviews), len(a_reviews)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "etz10ilur4dR",
        "outputId": "dab5f466-7e80-4f36-e12c-1c9f6aac7916"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000, 1400)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Explore Data"
      ],
      "metadata": {
        "id": "1vv8l5B7G208"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get total review count and positive and negative review counts\n",
        "total_review_count = len(reviews)\n",
        "positive_review_count = len([x for x in labels if x == 1])\n",
        "negative_review_count = len([x for x in labels if x == 0])\n",
        "\n",
        "# determine minimum and maximumtext length\n",
        "minimum_text_length = min([len(x) for x in list(reviews)])\n",
        "maximum_text_length = max([len(x) for x in list(reviews)])\n",
        "\n",
        "print(f'min review length (chars) - {minimum_text_length}\\nmax review length (chars) - {maximum_text_length}')\n",
        "print(f'total count - {total_review_count}\\npositive count - {positive_review_count}\\nnegative count - {negative_review_count}')"
      ],
      "metadata": {
        "id": "3J9eD_N2nQ_y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b64e46d5-15ef-4e1e-b7bb-28ee57ab4d8f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "min review length (chars) - 91\n",
            "max review length (chars) - 14957\n",
            "total count - 2000\n",
            "positive count - 1000\n",
            "negative count - 1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# separate positive and negative reviews\n",
        "positive_reviews = [reviews[i] for i in range(len(reviews)) if labels[i] == 1]\n",
        "negative_reviews = [reviews[i] for i in range(len(reviews)) if labels[i] == 0]\n",
        "\n",
        "\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "stopset = set(stopwords.words('english'))"
      ],
      "metadata": {
        "id": "LSAv3bFwzP6G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b834428-d8b6-472f-c363-9bcc5e9eaec4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ngram frequency\n",
        "positive_ngrams = []\n",
        "negative_ngrams = []\n",
        "\n",
        "n = 1\n",
        "\n",
        "# only get ngrams that contain alph numeric tokens that are not in the stop set\n",
        "for process in [(positive_reviews, positive_ngrams), (negative_reviews, negative_ngrams)]:\n",
        "  for rev in process[0]:\n",
        "    for ng in list(nltk.ngrams(rev.split(), n)):\n",
        "      if False not in [x.isalnum() for x in ng] and len([x for x in ng if x not in stopset]) == n:\n",
        "        process[1].append(ng)\n",
        "\n",
        "pos_frequencies = nltk.FreqDist(positive_ngrams)\n",
        "neg_frequencies = nltk.FreqDist(negative_ngrams)\n",
        "\n",
        "print('positive', pos_frequencies.most_common(50))\n",
        "print('negative', neg_frequencies.most_common(50))"
      ],
      "metadata": {
        "id": "RrVppzhd1eJp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b4ca64b-7def-4229-94ad-3654b67aa9a6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "positive [(('film',), 4857), (('one',), 2903), (('movie',), 2385), (('like',), 1712), (('story',), 1207), (('also',), 1200), (('good',), 1189), (('even',), 1174), (('time',), 1170), (('much',), 1026), (('character',), 1013), (('would',), 992), (('life',), 980), (('first',), 962), (('two',), 959), (('well',), 956), (('characters',), 953), (('see',), 951), (('way',), 915), (('get',), 883), (('films',), 872), (('best',), 807), (('many',), 780), (('really',), 775), (('make',), 772), (('little',), 768), (('people',), 767), (('great',), 743), (('new',), 718), (('never',), 716), (('scene',), 714), (('man',), 695), (('love',), 644), (('scenes',), 632), (('could',), 627), (('movies',), 627), (('world',), 619), (('still',), 585), (('us',), 581), (('plot',), 574), (('know',), 569), (('however',), 566), (('makes',), 560), (('another',), 559), (('back',), 557), (('performance',), 549), (('go',), 542), (('seen',), 537), (('seems',), 530), (('something',), 526)]\n",
            "negative [(('film',), 3992), (('movie',), 3044), (('one',), 2611), (('like',), 1831), (('even',), 1380), (('good',), 1124), (('time',), 1110), (('would',), 1049), (('get',), 1037), (('bad',), 1017), (('much',), 996), (('story',), 903), (('character',), 889), (('plot',), 874), (('two',), 865), (('characters',), 860), (('make',), 818), (('first',), 804), (('really',), 781), (('see',), 775), (('could',), 768), (('also',), 765), (('way',), 753), (('little',), 719), (('well',), 698), (('scene',), 658), (('people',), 651), (('never',), 644), (('films',), 641), (('know',), 638), (('scenes',), 630), (('action',), 604), (('director',), 564), (('man',), 560), (('new',), 557), (('movies',), 553), (('another',), 552), (('big',), 537), (('made',), 537), (('go',), 531), (('better',), 529), (('end',), 524), (('something',), 521), (('seems',), 502), (('every',), 495), (('work',), 493), (('nothing',), 492), (('best',), 491), (('life',), 487), (('many',), 487)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# average word length of reviews\n",
        "def avg_word_length(rev):\n",
        "    distinct_word_lengths = [len(w) for w in set(v.lower() for v in rev.split())]\n",
        "    avg_word_length = float(sum(distinct_word_lengths)) / len(distinct_word_lengths)\n",
        "    return avg_word_length\n",
        "\n",
        "\n",
        "avg_pos_rev_len = sum([avg_word_length(r) for r in positive_reviews]) / len(positive_reviews)\n",
        "avg_neg_rev_len = sum([avg_word_length(r) for r in negative_reviews]) / len(negative_reviews)\n",
        "avg_pos_rev_len, avg_neg_rev_len"
      ],
      "metadata": {
        "id": "FVdz4kup4f2e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c18a050f-3890-4f83-abd3-657de051e888"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5.69634338931218, 5.563958402025013)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def rev_len(rev):\n",
        "\n",
        "    w_list = rev.split()\n",
        "    total_words = len(w_list)\n",
        "\n",
        "    distinct_w_list = []\n",
        "    total_distinct_words = 0\n",
        "\n",
        "    for w in w_list:\n",
        "      lw = w.lower()\n",
        "      if lw not in distinct_w_list:\n",
        "        distinct_w_list.append(lw)\n",
        "        total_distinct_words += 1\n",
        "        #print(w)\n",
        "\n",
        "\n",
        "    return (total_words, total_distinct_words)\n",
        "\n",
        "avg_pos_rev_len = sum([rev_len(x)[0] for x in positive_reviews]) / len(positive_reviews)\n",
        "avg_neg_rev_len = sum([rev_len(x)[0] for x in negative_reviews]) / len(negative_reviews)\n",
        "\n",
        "pos_rev_dist_len = sum([rev_len(x)[1] for x in positive_reviews]) / len(positive_reviews)\n",
        "neg_rev_dist_len = sum([rev_len(x)[1] for x in negative_reviews]) / len(negative_reviews)\n",
        "\n",
        "print(avg_pos_rev_len, avg_neg_rev_len, pos_rev_dist_len, neg_rev_dist_len)"
      ],
      "metadata": {
        "id": "IUZ9k9uq-gjH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a577e39-6469-456e-aa90-ebb14f06481c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "787.051 705.63 358.53 333.46\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analyse Model Parameters"
      ],
      "metadata": {
        "id": "XeiRYkFap8Ok"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# produces a confusion matrix and determines Precision, Recall, Accuracy and F1-score of the given model\n",
        "\n",
        "def eval_model(model):\n",
        "  loss, accuracy = model.evaluate(X_test, y_test, verbose=False)\n",
        "  print(\"Testing Accuracy: {:.4f}\".format(accuracy))\n",
        "\n",
        "  # predict test data using model\n",
        "  y_pred = model.predict(X_test, batch_size=50, verbose=1)\n",
        "  y_pred_bool = []\n",
        "\n",
        "  # convert probablities to classes\n",
        "  for p in y_pred:\n",
        "    if p >= 0.5:\n",
        "      y_pred_bool.append(1)\n",
        "    else:\n",
        "      y_pred_bool.append(0)\n",
        "\n",
        "  # print results\n",
        "  cm = confusion_matrix(y_test, y_pred_bool)\n",
        "  cf = classification_report(y_test, y_pred_bool)\n",
        "\n",
        "  print('\\t  Predicted')\n",
        "  print('\\t   0    1  ')\n",
        "  print(f'\\t0 {cm[0]}')\n",
        "  print('True\\t')\n",
        "  print(f'\\t1 {cm[1]}')\n",
        "\n",
        "  print(cf)\n",
        "\n",
        "  return (accuracy, cm, cf)"
      ],
      "metadata": {
        "id": "FF54yGFInwse"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pre-process testing data\n",
        "def analysis_data():\n",
        "  # split data into training and testing\n",
        "  reviews_train, reviews_test, y_train, y_test = train_test_split(a_reviews, a_labels, test_size=0.20)\n",
        "\n",
        "  # tokenize the data \n",
        "  tokenizer = Tokenizer(num_words=43297)\n",
        "  tokenizer.fit_on_texts(reviews)\n",
        "  X_train = tokenizer.texts_to_sequences(reviews_train)\n",
        "  X_test = tokenizer.texts_to_sequences(reviews_test)\n",
        "\n",
        "  vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "  # the max length of a reviews, parameter for the embedding layer\n",
        "  maxlen = max([len(x) for x in X_train] + [len(x) for x in X_test])\n",
        "\n",
        "  # pad the tokenized data\n",
        "  X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
        "  X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)\n",
        "\n",
        "  return (vocab_size, maxlen, X_train, X_test, y_train, y_test)\n",
        "\n",
        "vocab_size, maxlen, X_train, X_test, y_train, y_test = analysis_data()\n",
        "print(vocab_size, maxlen, len(X_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FpeOtYSzqL3S",
        "outputId": "891332d4-dd15-4114-b846-b4143e3c65f7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "43297 2392 1120\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test different numbers of LSTM layers\n",
        "\n",
        "results = []\n",
        "\n",
        "def lstm_layers_1():\n",
        "  embedding_dim = 10\n",
        "  model = Sequential()\n",
        "  model.add(layers.Embedding(vocab_size, embedding_dim, input_length=maxlen))\n",
        "  model.add(layers.LSTM(4, return_sequences=True, dropout=0.2))\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dense(1, activation='sigmoid'))\n",
        "  model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "def lstm_layers_2():\n",
        "  embedding_dim = 10\n",
        "  model = Sequential()\n",
        "  model.add(layers.Embedding(vocab_size, embedding_dim, input_length=maxlen))\n",
        "  model.add(layers.LSTM(4, return_sequences=True, dropout=0.2))\n",
        "  model.add(layers.LSTM(4, return_sequences=True, dropout=0.2))\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dense(1, activation='sigmoid'))\n",
        "  model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "def lstm_layers_3():\n",
        "  embedding_dim = 10\n",
        "  model = Sequential()\n",
        "  model.add(layers.Embedding(vocab_size, embedding_dim, input_length=maxlen))\n",
        "  model.add(layers.LSTM(4, return_sequences=True, dropout=0.2))\n",
        "  model.add(layers.LSTM(4, return_sequences=True, dropout=0.2))\n",
        "  model.add(layers.LSTM(4, return_sequences=True, dropout=0.2))\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dense(1, activation='sigmoid'))\n",
        "  model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "models = [lstm_layers_1, lstm_layers_2, lstm_layers_3]\n",
        "avg_acc = []\n",
        "tests = 10\n",
        "\n",
        "for model_func in models:\n",
        "\n",
        "  total_accuracy = 0\n",
        "\n",
        "  for i in range(tests):\n",
        "    model = model_func()\n",
        "    training = model.fit(X_train, y_train, epochs=5, verbose=True, validation_split=0.1, batch_size=50)\n",
        "    accuracy, cm, cf = eval_model(model)\n",
        "\n",
        "    print(accuracy)\n",
        "\n",
        "    total_accuracy += accuracy\n",
        "\n",
        "  mean_accuracy = total_accuracy / tests\n",
        "  print('MEAN ACCURACY -', mean_accuracy)\n",
        "  avg_acc.append(mean_accuracy)\n",
        "\n",
        "print(avg_acc)"
      ],
      "metadata": {
        "id": "HOqbO7DB1-H4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test different embedding dimensions\n",
        "\n",
        "results = []\n",
        "\n",
        "def dim_10():\n",
        "  embedding_dim = 10\n",
        "  model = Sequential()\n",
        "  model.add(layers.Embedding(vocab_size, embedding_dim, input_length=maxlen))\n",
        "  model.add(layers.LSTM(4, return_sequences=True, dropout=0.2))\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dense(1, activation='sigmoid'))\n",
        "  model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "def dim_100():\n",
        "  embedding_dim = 100\n",
        "  model = Sequential()\n",
        "  model.add(layers.Embedding(vocab_size, embedding_dim, input_length=maxlen))\n",
        "  model.add(layers.LSTM(4, return_sequences=True, dropout=0.2))\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dense(1, activation='sigmoid'))\n",
        "  model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "def dim_300():\n",
        "  embedding_dim = 300\n",
        "  model = Sequential()\n",
        "  model.add(layers.Embedding(vocab_size, embedding_dim, input_length=maxlen))\n",
        "  model.add(layers.LSTM(4, return_sequences=True, dropout=0.2))\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dense(1, activation='sigmoid'))\n",
        "  model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "models = [dim_10, dim_100, dim_300]\n",
        "avg_acc = []\n",
        "tests = 10\n",
        "\n",
        "for model_func in models:\n",
        "\n",
        "  total_accuracy = 0\n",
        "\n",
        "  for i in range(tests):\n",
        "    model = model_func()\n",
        "    training = model.fit(X_train, y_train, epochs=5, verbose=True, validation_split=0.1, batch_size=50)\n",
        "    accuracy, cm, cf = eval_model(model)\n",
        "\n",
        "    print(accuracy)\n",
        "\n",
        "    total_accuracy += accuracy\n",
        "\n",
        "  mean_accuracy = total_accuracy / tests\n",
        "  print('MEAN ACCURACY -', mean_accuracy)\n",
        "  avg_acc.append(mean_accuracy)\n",
        "\n",
        "print(avg_acc)"
      ],
      "metadata": {
        "id": "yoPZf7Kw01BO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Model"
      ],
      "metadata": {
        "id": "pNWG4e4GG9w8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pre processing the data for input to the embedding layer\n",
        "def process_data():\n",
        "  # split the data\n",
        "  reviews_train, reviews_test, y_train, y_test = train_test_split(reviews, labels, test_size=0.20)\n",
        "\n",
        "  # tokenize the dataset\n",
        "  tokenizer = Tokenizer(num_words=43297)\n",
        "  tokenizer.fit_on_texts(reviews_train)\n",
        "  X_train = tokenizer.texts_to_sequences(reviews_train)\n",
        "  X_test = tokenizer.texts_to_sequences(reviews_test)\n",
        "\n",
        "  vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "  # the max length of a reviews, parameter for the embedding layer\n",
        "  maxlen = max([len(x) for x in X_train] + [len(x) for x in X_test])\n",
        "\n",
        "  # pad the tokenized data with 0s\n",
        "  X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
        "  X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)\n",
        "\n",
        "  return (vocab_size, maxlen, X_train, X_test, y_train, y_test)\n",
        "\n",
        "vocab_size, maxlen, X_train, X_test, y_train, y_test = process_data()\n",
        "print(vocab_size, maxlen, len(X_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zzDhA9N4HgF",
        "outputId": "26be38e0-3462-42db-a873-10d46687e53f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "39386 2392 1600\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# produces a confusion matrix and determines Precision, Recall, Accuracy and F1-score of model\n",
        "\n",
        "def eval_model(model):\n",
        "  loss, accuracy = model.evaluate(X_test, y_test, verbose=False)\n",
        "  print(\"Testing Accuracy: {:.4f}\".format(accuracy))\n",
        "\n",
        "  # predict test data using model\n",
        "  y_pred = model.predict(X_test, batch_size=50, verbose=1)\n",
        "  y_pred_bool = []\n",
        "\n",
        "  # convert probablities to classes\n",
        "  for p in y_pred:\n",
        "    if p >= 0.5:\n",
        "      y_pred_bool.append(1)\n",
        "    else:\n",
        "      y_pred_bool.append(0)\n",
        "\n",
        "  # print results\n",
        "  cm = confusion_matrix(y_test, y_pred_bool)\n",
        "  cf = classification_report(y_test, y_pred_bool)\n",
        "\n",
        "  print('\\t  Predicted')\n",
        "  print('\\t   0    1  ')\n",
        "  print(f'\\t0 {cm[0]}')\n",
        "  print('True\\t')\n",
        "  print(f'\\t1 {cm[1]}')\n",
        "\n",
        "  print(cf)\n",
        "\n",
        "  return (accuracy, cm, cf)"
      ],
      "metadata": {
        "id": "H8BIR64jioUn"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train[568])"
      ],
      "metadata": {
        "id": "K03VTmD5NqsR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e7b94f4-1990-4f65-dd95-9ab105e9a8a6"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1768 4753  643 ...    0    0    0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# early stopping callbacks\n",
        "from keras.callbacks import EarlyStopping\n",
        "earlystop = EarlyStopping(monitor='loss', patience=3)"
      ],
      "metadata": {
        "id": "cWWWQ8QUzqLo"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -- define the model --\n",
        "\n",
        "def lstm_classifier():\n",
        "  embedding_dim = 300\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(layers.Embedding(vocab_size, embedding_dim, input_length=maxlen))\n",
        "  model.add(layers.LSTM(4, return_sequences=True, dropout=0.2))\n",
        "  model.add(layers.LSTM(4, return_sequences=True, dropout=0.2))\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dense(100, activation='relu'))\n",
        "  model.add(layers.Dense(1, activation='sigmoid'))\n",
        "  model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "  model.summary()\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "-qUWg3QdnVo7"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -- training --\n",
        "\n",
        "model2 = lstm_classifier()\n",
        "training = model2.fit(X_train, y_train, epochs=5, verbose=True, validation_split=0.1, batch_size=50, callbacks=[earlystop])"
      ],
      "metadata": {
        "id": "clt_PmK_ny0i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c7627f8-574a-4a3c-bf9b-10583da77846"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 2392, 300)         11815800  \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 2392, 4)           4880      \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 2392, 4)           144       \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 9568)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 100)               956900    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 101       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 12,777,825\n",
            "Trainable params: 12,777,825\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "29/29 [==============================] - 112s 4s/step - loss: 0.6522 - accuracy: 0.5868 - val_loss: 0.5051 - val_accuracy: 0.7688\n",
            "Epoch 2/5\n",
            "29/29 [==============================] - 108s 4s/step - loss: 0.2028 - accuracy: 0.9340 - val_loss: 0.4079 - val_accuracy: 0.8125\n",
            "Epoch 3/5\n",
            "29/29 [==============================] - 110s 4s/step - loss: 0.0112 - accuracy: 0.9993 - val_loss: 0.4919 - val_accuracy: 0.8313\n",
            "Epoch 4/5\n",
            "29/29 [==============================] - 105s 4s/step - loss: 0.0062 - accuracy: 0.9972 - val_loss: 0.9355 - val_accuracy: 0.7063\n",
            "Epoch 5/5\n",
            "29/29 [==============================] - 112s 4s/step - loss: 0.0042 - accuracy: 0.9993 - val_loss: 0.6425 - val_accuracy: 0.7750\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_model(model2)"
      ],
      "metadata": {
        "id": "cajkxb8tAIJO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ee32f2c-8dba-497d-d531-c68103e31066"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing Accuracy: 0.8175\n",
            "8/8 [==============================] - 4s 420ms/step\n",
            "\t  Predicted\n",
            "\t   0    1  \n",
            "\t0 [191  21]\n",
            "True\t\n",
            "\t1 [ 52 136]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.90      0.84       212\n",
            "           1       0.87      0.72      0.79       188\n",
            "\n",
            "    accuracy                           0.82       400\n",
            "   macro avg       0.83      0.81      0.81       400\n",
            "weighted avg       0.82      0.82      0.82       400\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.8174999952316284, array([[191,  21],\n",
              "        [ 52, 136]]), '              precision    recall  f1-score   support\\n\\n           0       0.79      0.90      0.84       212\\n           1       0.87      0.72      0.79       188\\n\\n    accuracy                           0.82       400\\n   macro avg       0.83      0.81      0.81       400\\nweighted avg       0.82      0.82      0.82       400\\n')"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    }
  ]
}